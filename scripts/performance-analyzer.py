#!/usr/bin/env python3
"""
WezTerm Parallel ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ„ãƒ¼ãƒ«
ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®å¯è¦–åŒ–ã¨è©³ç´°åˆ†æã‚’è¡Œã„ã¾ã™ã€‚
"""

import json
import sys
import argparse
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import seaborn as sns

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
plt.style.use('dark_background')
sns.set_palette("husl")

class PerformanceAnalyzer:
    def __init__(self, results_file):
        """åˆ†æå™¨ã‚’åˆæœŸåŒ–"""
        self.results_file = Path(results_file)
        self.results = self._load_results()
        self.output_dir = self.results_file.parent / "analysis"
        self.output_dir.mkdir(exist_ok=True)
    
    def _load_results(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.results_file) as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.results_file}")
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"âŒ JSONãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—: {e}")
            sys.exit(1)
    
    def analyze_startup_time(self):
        """èµ·å‹•æ™‚é–“ã®åˆ†æã¨ã‚°ãƒ©ãƒ•ä½œæˆ"""
        startup_data = self.results['benchmarks']['startup_time']
        valid_times = [t for t in startup_data if t is not None]
        
        if not valid_times:
            print("âš ï¸ èµ·å‹•æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("ğŸ“Š èµ·å‹•æ™‚é–“åˆ†æ")
        print(f"   å¹³å‡: {np.mean(valid_times):.3f}ç§’")
        print(f"   ä¸­å¤®å€¤: {np.median(valid_times):.3f}ç§’")
        print(f"   æ¨™æº–åå·®: {np.std(valid_times):.3f}ç§’")
        print(f"   ç¯„å›²: {np.min(valid_times):.3f}ç§’ - {np.max(valid_times):.3f}ç§’")
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle('èµ·å‹•æ™‚é–“åˆ†æ', fontsize=16, fontweight='bold')
        
        # æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
        ax1.plot(range(1, len(valid_times) + 1), valid_times, 
                marker='o', linewidth=2, markersize=8, color='#00ff00')
        ax1.axhline(y=np.mean(valid_times), color='#ff6b35', 
                   linestyle='--', linewidth=2, label=f'å¹³å‡: {np.mean(valid_times):.3f}s')
        ax1.set_xlabel('å®Ÿè¡Œå›æ•°')
        ax1.set_ylabel('èµ·å‹•æ™‚é–“ (ç§’)')
        ax1.set_title('èµ·å‹•æ™‚é–“ã®æ¨ç§»')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        ax2.hist(valid_times, bins=10, edgecolor='white', alpha=0.7, color='#89b4fa')
        ax2.axvline(x=np.mean(valid_times), color='#ff6b35', 
                   linestyle='--', linewidth=2, label=f'å¹³å‡: {np.mean(valid_times):.3f}s')
        ax2.set_xlabel('èµ·å‹•æ™‚é–“ (ç§’)')
        ax2.set_ylabel('é »åº¦')
        ax2.set_title('èµ·å‹•æ™‚é–“ã®åˆ†å¸ƒ')
        ax2.legend()
        
        plt.tight_layout()
        output_file = self.output_dir / "startup_time_analysis.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"   ã‚°ãƒ©ãƒ•ä¿å­˜: {output_file}")
        plt.close()
    
    def analyze_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®åˆ†æã¨ã‚°ãƒ©ãƒ•ä½œæˆ"""
        memory_data = self.results['benchmarks']['memory_usage']
        
        if not memory_data or 'samples' not in memory_data:
            print("âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        samples = memory_data['samples']
        
        print("ğŸ“Š ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æ")
        print(f"   å¹³å‡: {memory_data['avg_mb']:.2f}MB")
        print(f"   æœ€å°: {memory_data['min_mb']:.2f}MB")
        print(f"   æœ€å¤§: {memory_data['max_mb']:.2f}MB")
        print(f"   å¤‰å‹•ä¿‚æ•°: {(np.std(samples) / np.mean(samples) * 100):.2f}%")
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))
        fig.suptitle('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ†æ', fontsize=16, fontweight='bold')
        
        # æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
        time_points = np.arange(len(samples))
        ax1.plot(time_points, samples, linewidth=2, color='#a6e3a1')
        ax1.fill_between(time_points, samples, alpha=0.3, color='#a6e3a1')
        ax1.axhline(y=np.mean(samples), color='#ff6b35', 
                   linestyle='--', linewidth=2, label=f'å¹³å‡: {np.mean(samples):.2f}MB')
        ax1.set_xlabel('æ™‚é–“ (ç§’)')
        ax1.set_ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)')
        ax1.set_title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®æ™‚ç³»åˆ—å¤‰åŒ–')
        ax1.grid(True, alpha=0.3)
        ax1.legend()
        
        # ç§»å‹•å¹³å‡ã¨ãƒˆãƒ¬ãƒ³ãƒ‰
        window_size = min(10, len(samples) // 4)
        if window_size > 1:
            moving_avg = pd.Series(samples).rolling(window=window_size).mean()
            ax2.plot(time_points, samples, alpha=0.5, color='#a6e3a1', label='å®Ÿæ¸¬å€¤')
            ax2.plot(time_points, moving_avg, linewidth=3, color='#89b4fa', 
                    label=f'ç§»å‹•å¹³å‡ ({window_size}ç§’)')
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            z = np.polyfit(time_points, samples, 1)
            trend_line = np.poly1d(z)
            ax2.plot(time_points, trend_line(time_points), 
                    linewidth=2, linestyle=':', color='#f9e2af', 
                    label=f'ãƒˆãƒ¬ãƒ³ãƒ‰: {z[0]:.3f}MB/s')
        
        ax2.set_xlabel('æ™‚é–“ (ç§’)')
        ax2.set_ylabel('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ (MB)')
        ax2.set_title('ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ')
        ax2.grid(True, alpha=0.3)
        ax2.legend()
        
        plt.tight_layout()
        output_file = self.output_dir / "memory_usage_analysis.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"   ã‚°ãƒ©ãƒ•ä¿å­˜: {output_file}")
        plt.close()
    
    def analyze_api_response(self):
        """APIå¿œç­”æ€§èƒ½ã®åˆ†æã¨ã‚°ãƒ©ãƒ•ä½œæˆ"""
        api_data = self.results['benchmarks']['api_response']
        
        if not api_data:
            print("âš ï¸ APIå¿œç­”ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("ğŸ“Š APIå¿œç­”æ€§èƒ½åˆ†æ")
        
        # ãƒ‡ãƒ¼ã‚¿æ•´ç†
        endpoints = []
        response_times = []
        success_rates = []
        
        for item in api_data:
            if 'error' not in item:
                endpoints.append(item['endpoint'].split('/')[-1])  # ãƒ‘ã‚¹ã®æœ€å¾Œã®éƒ¨åˆ†
                response_times.append(item['avg_response_time'] * 1000)  # ãƒŸãƒªç§’å¤‰æ›
                success_rates.append(item['success_rate'] * 100)  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰æ›
                print(f"   {item['endpoint']}: {item['avg_response_time']*1000:.2f}ms (æˆåŠŸç‡: {item['success_rate']*100:.1f}%)")
        
        if not endpoints:
            print("âš ï¸ æœ‰åŠ¹ãªAPIå¿œç­”ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle('APIå¿œç­”æ€§èƒ½åˆ†æ', fontsize=16, fontweight='bold')
        
        # å¿œç­”æ™‚é–“ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        bars1 = ax1.bar(endpoints, response_times, color='#f38ba8', alpha=0.8)
        ax1.set_ylabel('å¹³å‡å¿œç­”æ™‚é–“ (ms)')
        ax1.set_title('ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¥å¿œç­”æ™‚é–“')
        ax1.tick_params(axis='x', rotation=45)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, time in zip(bars1, response_times):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    f'{time:.1f}ms', ha='center', va='bottom')
        
        # æˆåŠŸç‡ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        bars2 = ax2.bar(endpoints, success_rates, color='#94e2d5', alpha=0.8)
        ax2.set_ylabel('æˆåŠŸç‡ (%)')
        ax2.set_title('ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆåˆ¥æˆåŠŸç‡')
        ax2.set_ylim(0, 100)
        ax2.tick_params(axis='x', rotation=45)
        
        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, rate in zip(bars2, success_rates):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    f'{rate:.1f}%', ha='center', va='bottom')
        
        plt.tight_layout()
        output_file = self.output_dir / "api_response_analysis.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"   ã‚°ãƒ©ãƒ•ä¿å­˜: {output_file}")
        plt.close()
    
    def analyze_stress_test(self):
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆã®åˆ†æã¨ã‚°ãƒ©ãƒ•ä½œæˆ"""
        stress_data = self.results['benchmarks']['stress_test']
        
        if not stress_data:
            print("âš ï¸ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("ğŸ“Š ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆåˆ†æ")
        
        # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆæ€§èƒ½
        if 'workspace_creation' in stress_data:
            ws_data = stress_data['workspace_creation']
            print(f"   ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆ:")
            print(f"     æˆåŠŸç‡: {ws_data['success_count']}/{ws_data['target_count']} ({ws_data['success_count']/ws_data['target_count']*100:.1f}%)")
            print(f"     ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {ws_data['throughput_ops_per_second']:.2f} ops/sec")
        
        # APIè² è·ãƒ†ã‚¹ãƒˆ
        if 'api_load_test' in stress_data:
            api_data = stress_data['api_load_test']
            print(f"   APIè² è·ãƒ†ã‚¹ãƒˆ:")
            print(f"     æˆåŠŸç‡: {api_data['success_rate']*100:.1f}%")
            print(f"     ç¶™ç¶šæ™‚é–“: {api_data['duration_seconds']:.1f}ç§’")
            if api_data.get('total_requests', 0) > 0:
                print(f"     å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {api_data['total_requests']/api_data['duration_seconds']:.1f} req/sec")
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        fig.suptitle('ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœ', fontsize=16, fontweight='bold')
        
        # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆçµæœ
        if 'workspace_creation' in stress_data:
            ws_data = stress_data['workspace_creation']
            success_count = ws_data['success_count']
            failure_count = ws_data['target_count'] - success_count
            
            ax1.pie([success_count, failure_count], 
                   labels=['æˆåŠŸ', 'å¤±æ•—'], 
                   colors=['#a6e3a1', '#f38ba8'],
                   autopct='%1.1f%%',
                   startangle=90)
            ax1.set_title(f'ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆçµæœ\n(ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {ws_data["throughput_ops_per_second"]:.2f} ops/sec)')
        
        # APIè² è·ãƒ†ã‚¹ãƒˆçµæœ
        if 'api_load_test' in stress_data:
            api_data = stress_data['api_load_test']
            success_rate = api_data['success_rate'] * 100
            failure_rate = 100 - success_rate
            
            ax2.pie([success_rate, failure_rate], 
                   labels=['æˆåŠŸ', 'å¤±æ•—'], 
                   colors=['#94e2d5', '#f9e2af'],
                   autopct='%1.1f%%',
                   startangle=90)
            ax2.set_title(f'APIè² è·ãƒ†ã‚¹ãƒˆçµæœ\n(ç¶™ç¶šæ™‚é–“: {api_data["duration_seconds"]:.1f}ç§’)')
        
        plt.tight_layout()
        output_file = self.output_dir / "stress_test_analysis.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"   ã‚°ãƒ©ãƒ•ä¿å­˜: {output_file}")
        plt.close()
    
    def generate_performance_score(self):
        """ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        score = 100  # æº€ç‚¹ã‹ã‚‰æ¸›ç‚¹æ–¹å¼
        
        print("ğŸ“Š ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—")
        
        # èµ·å‹•æ™‚é–“è©•ä¾¡ (ç›®æ¨™: 3ç§’ä»¥ä¸‹)
        startup_data = self.results['benchmarks']['startup_time']
        valid_times = [t for t in startup_data if t is not None]
        if valid_times:
            avg_startup = np.mean(valid_times)
            if avg_startup > 5:
                score -= 30
                print(f"   èµ·å‹•æ™‚é–“: å¤§å¹…æ¸›ç‚¹ ({avg_startup:.2f}ç§’ > 5ç§’)")
            elif avg_startup > 3:
                score -= 15
                print(f"   èµ·å‹•æ™‚é–“: æ¸›ç‚¹ ({avg_startup:.2f}ç§’ > 3ç§’)")
            else:
                print(f"   èµ·å‹•æ™‚é–“: è‰¯å¥½ ({avg_startup:.2f}ç§’)")
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è©•ä¾¡ (ç›®æ¨™: 100MBä»¥ä¸‹)
        memory_data = self.results['benchmarks']['memory_usage']
        if memory_data:
            avg_memory = memory_data['avg_mb']
            if avg_memory > 200:
                score -= 25
                print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: å¤§å¹…æ¸›ç‚¹ ({avg_memory:.1f}MB > 200MB)")
            elif avg_memory > 100:
                score -= 10
                print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: æ¸›ç‚¹ ({avg_memory:.1f}MB > 100MB)")
            else:
                print(f"   ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: è‰¯å¥½ ({avg_memory:.1f}MB)")
        
        # APIå¿œç­”æ€§èƒ½è©•ä¾¡ (ç›®æ¨™: 100msä»¥ä¸‹)
        api_data = self.results['benchmarks']['api_response']
        if api_data:
            slow_apis = 0
            for item in api_data:
                if 'avg_response_time' in item and item['avg_response_time'] > 0.1:
                    slow_apis += 1
            if slow_apis > 0:
                score -= slow_apis * 5
                print(f"   APIå¿œç­”æ€§èƒ½: æ¸›ç‚¹ ({slow_apis}å€‹ã®APIãŒ100msè¶…é)")
            else:
                print("   APIå¿œç­”æ€§èƒ½: è‰¯å¥½")
        
        # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆè©•ä¾¡
        stress_data = self.results['benchmarks']['stress_test']
        if stress_data:
            if 'workspace_creation' in stress_data:
                ws_success_rate = stress_data['workspace_creation']['success_count'] / stress_data['workspace_creation']['target_count']
                if ws_success_rate < 0.8:
                    score -= 20
                    print(f"   ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ: æ¸›ç‚¹ (ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆæˆåŠŸç‡ {ws_success_rate*100:.1f}% < 80%)")
                else:
                    print(f"   ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ: è‰¯å¥½ (ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆæˆåŠŸç‡ {ws_success_rate*100:.1f}%)")
        
        score = max(0, score)  # 0ç‚¹æœªæº€ã«ã¯ã—ãªã„
        
        print(f"\nğŸ¯ ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢: {score}/100")
        
        if score >= 90:
            print("   è©•ä¾¡: å„ªç§€ â­â­â­")
        elif score >= 70:
            print("   è©•ä¾¡: è‰¯å¥½ â­â­")
        elif score >= 50:
            print("   è©•ä¾¡: æ”¹å–„ã®ä½™åœ°ã‚ã‚Š â­")
        else:
            print("   è©•ä¾¡: è¦æ”¹å–„")
        
        return score
    
    def generate_comprehensive_report(self):
        """åŒ…æ‹¬çš„ãªHTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        html_template = """
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WezTerm Parallel ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #1e1e2e;
            color: #cdd6f4;
            margin: 0;
            padding: 20px;
            line-height: 1.6;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: #313244;
            border-radius: 12px;
            padding: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #89b4fa;
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 30px;
        }
        h2 {
            color: #a6e3a1;
            border-bottom: 2px solid #a6e3a1;
            padding-bottom: 10px;
        }
        h3 {
            color: #f9e2af;
        }
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .metric-card {
            background: #45475a;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
        }
        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #94e2d5;
        }
        .metric-label {
            color: #bac2de;
            margin-top: 5px;
        }
        .score-circle {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            margin: 20px auto;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            font-weight: bold;
            color: white;
        }
        .score-excellent { background: linear-gradient(45deg, #a6e3a1, #94e2d5); }
        .score-good { background: linear-gradient(45deg, #f9e2af, #fab387); }
        .score-average { background: linear-gradient(45deg, #fab387, #f38ba8); }
        .score-poor { background: linear-gradient(45deg, #f38ba8, #eba0ac); }
        .image-gallery {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .image-card {
            background: #45475a;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
        }
        .image-card img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }
        .system-info {
            background: #45475a;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }
        .timestamp {
            text-align: center;
            color: #bac2de;
            font-style: italic;
            margin-bottom: 30px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>WezTerm Parallel ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <div class="timestamp">ç”Ÿæˆæ—¥æ™‚: {timestamp}</div>
        
        <h2>ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢</h2>
        <div class="score-circle {score_class}">
            {score}/100
        </div>
        
        <h2>ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±</h2>
        <div class="system-info">
            {system_info}
        </div>
        
        <h2>ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹</h2>
        <div class="metric-grid">
            {metrics_cards}
        </div>
        
        <h2>è©³ç´°åˆ†æã‚°ãƒ©ãƒ•</h2>
        <div class="image-gallery">
            {analysis_images}
        </div>
        
        <h2>æ¨å¥¨æ”¹å–„ç‚¹</h2>
        <div style="background: #45475a; padding: 20px; border-radius: 8px;">
            {recommendations}
        </div>
    </div>
</body>
</html>
        """
        
        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = self.generate_performance_score()
        
        # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸã‚¯ãƒ©ã‚¹
        if score >= 90:
            score_class = "score-excellent"
        elif score >= 70:
            score_class = "score-good"
        elif score >= 50:
            score_class = "score-average"
        else:
            score_class = "score-poor"
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
        system_info = "<ul>"
        for key, value in self.results['system_info'].items():
            system_info += f"<li><strong>{key}</strong>: {value}</li>"
        system_info += "</ul>"
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰
        metrics_cards = ""
        
        # èµ·å‹•æ™‚é–“ã‚«ãƒ¼ãƒ‰
        startup_data = self.results['benchmarks']['startup_time']
        valid_times = [t for t in startup_data if t is not None]
        if valid_times:
            metrics_cards += f"""
            <div class="metric-card">
                <div class="metric-value">{np.mean(valid_times):.2f}s</div>
                <div class="metric-label">å¹³å‡èµ·å‹•æ™‚é–“</div>
            </div>
            """
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚«ãƒ¼ãƒ‰
        memory_data = self.results['benchmarks']['memory_usage']
        if memory_data:
            metrics_cards += f"""
            <div class="metric-card">
                <div class="metric-value">{memory_data['avg_mb']:.1f}MB</div>
                <div class="metric-label">å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡</div>
            </div>
            """
        
        # APIå¿œç­”æ™‚é–“ã‚«ãƒ¼ãƒ‰
        api_data = self.results['benchmarks']['api_response']
        if api_data:
            avg_response = np.mean([item['avg_response_time'] for item in api_data if 'avg_response_time' in item]) * 1000
            metrics_cards += f"""
            <div class="metric-card">
                <div class="metric-value">{avg_response:.1f}ms</div>
                <div class="metric-label">å¹³å‡APIå¿œç­”æ™‚é–“</div>
            </div>
            """
        
        # åˆ†æç”»åƒ
        analysis_images = ""
        image_files = ['startup_time_analysis.png', 'memory_usage_analysis.png', 
                      'api_response_analysis.png', 'stress_test_analysis.png']
        
        for img_file in image_files:
            img_path = self.output_dir / img_file
            if img_path.exists():
                analysis_images += f"""
                <div class="image-card">
                    <h3>{img_file.replace('_', ' ').replace('.png', '').title()}</h3>
                    <img src="{img_file}" alt="{img_file}">
                </div>
                """
        
        # æ¨å¥¨æ”¹å–„ç‚¹
        recommendations = "<ul>"
        if valid_times and np.mean(valid_times) > 3:
            recommendations += "<li>èµ·å‹•æ™‚é–“ã®æœ€é©åŒ–: é…å»¶åˆæœŸåŒ–ã®æ´»ç”¨ã‚„ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å‡¦ç†ã®æ”¹å–„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„</li>"
        if memory_data and memory_data['avg_mb'] > 100:
            recommendations += "<li>ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›: ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ã®æœ€é©åŒ–ã‚„ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„</li>"
        if api_data:
            slow_apis = [item for item in api_data if 'avg_response_time' in item and item['avg_response_time'] > 0.1]
            if slow_apis:
                recommendations += f"<li>APIå¿œç­”æ€§èƒ½ã®æ”¹å–„: {len(slow_apis)}å€‹ã®APIãŒç›®æ¨™å€¤(100ms)ã‚’è¶…éã—ã¦ã„ã¾ã™</li>"
        if score < 70:
            recommendations += "<li>åŒ…æ‹¬çš„ãªæ€§èƒ½ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è¦‹ç›´ã—ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šã®æœ€é©åŒ–ã‚’æ¨å¥¨ã—ã¾ã™</li>"
        
        if recommendations == "<ul>":
            recommendations += "<li>ç¾åœ¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯è‰¯å¥½ã§ã™ã€‚å®šæœŸçš„ãªç›£è¦–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚</li>"
        recommendations += "</ul>"
        
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        html_content = html_template.format(
            timestamp=datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
            score=score,
            score_class=score_class,
            system_info=system_info,
            metrics_cards=metrics_cards,
            analysis_images=analysis_images,
            recommendations=recommendations
        )
        
        html_file = self.output_dir / "performance_report.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"ğŸ“„ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {html_file}")
    
    def run_complete_analysis(self):
        """å®Œå…¨ãªåˆ†æã‚’å®Ÿè¡Œ"""
        print("ğŸš€ WezTerm Parallel ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æé–‹å§‹")
        print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {self.results_file}")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
        print()
        
        self.analyze_startup_time()
        print()
        self.analyze_memory_usage()
        print()
        self.analyze_api_response()
        print()
        self.analyze_stress_test()
        print()
        self.generate_comprehensive_report()
        
        print("\nâœ… åˆ†æå®Œäº†!")
        print(f"ğŸ“Š åˆ†æçµæœ: {self.output_dir}/")
        print(f"ğŸ“„ HTMLãƒ¬ãƒãƒ¼ãƒˆ: {self.output_dir}/performance_report.html")

def main():
    parser = argparse.ArgumentParser(description='WezTerm Parallel ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ„ãƒ¼ãƒ«')
    parser.add_argument('results_file', help='ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœJSONãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--startup-only', action='store_true', help='èµ·å‹•æ™‚é–“åˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--memory-only', action='store_true', help='ãƒ¡ãƒ¢ãƒªåˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--api-only', action='store_true', help='APIåˆ†æã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--score-only', action='store_true', help='ã‚¹ã‚³ã‚¢è¨ˆç®—ã®ã¿å®Ÿè¡Œ')
    
    args = parser.parse_args()
    
    try:
        analyzer = PerformanceAnalyzer(args.results_file)
        
        if args.startup_only:
            analyzer.analyze_startup_time()
        elif args.memory_only:
            analyzer.analyze_memory_usage()
        elif args.api_only:
            analyzer.analyze_api_response()
        elif args.score_only:
            analyzer.generate_performance_score()
        else:
            analyzer.run_complete_analysis()
            
    except KeyboardInterrupt:
        print("\nâŒ åˆ†æãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()